import os

# Cache directory for storing search results
CACHE_DIR = os.path.expanduser("~/aipubtrends")
os.makedirs(CACHE_DIR, exist_ok=True)

# TODO fix me!!!!
PUBTRENDS_API = os.getenv(
    "PUBTRENDS_API",
    "http://127.0.0.1:5000"
)

GOOGLE_SUMMARIZE_CATEGORIES_ENDPOINT = os.getenv(
    "GOOGLE_SUMMARIZE_CATEGORIES_ENDPOINT",
    ""
)

GOOGLE_SEMANTIC_SEARCH_ENDPOINT = os.getenv(
    "GOOGLE_SEMANTIC_SEARCH_ENDPOINT",
    ""
)

GOOGLE_MODEL_SUMMARIZE_TOPIC_TITLE_ENDPOINT = os.getenv(
    "GOOGLE_MODEL_SUMMARIZE_TOPIC_TITLE_ENDPOINT",
    ""
)

GOOGLE_MODEL_SUMMARIZE_TOPIC_ENDPOINT = os.getenv(
    "GOOGLE_MODEL_SUMMARIZE_TOPIC_ENDPOINT",
    ""
)

GOOGLE_SUMMARIZE_CATEGORY_GENES = "GENES_EXTRACTION"
GOOGLE_SUMMARIZE_CATEGORY_SUBSTANCES = "SUBSTANCES_EXTRACTION"
GOOGLE_SUMMARIZE_CATEGORY_CONDITIONS = "CONDITIONS_EXTRACTION"
GOOGLE_SUMMARIZE_CATEGORY_PROTEINS = "PROTEINS_EXTRACTION"

SUMMARY_TOPICS = "TOPICS_SUMMARIES"

STEP_NOT_STARTED = 'not_started'
STEP_PENDING = 'pending'
STEP_COMPLETE = 'complete'
STEP_ERROR = 'error'

START_STEP = 'Starting analysis'
PUBTRENDS_STEP = 'Waiting for the PubTrends analysis results'
SUMMARIZE_STEP = 'Building summaries'

SEMANTIC_SEARCH_STEP = 'Semantic search'
STEP_SEMANTIC_SEARCH_PASSED_FURTHER = 'semantic_search_ids_passed_further'

def create_text_steps():
    return {
        START_STEP: STEP_NOT_STARTED,
        PUBTRENDS_STEP: STEP_NOT_STARTED,
        SUMMARIZE_STEP: STEP_NOT_STARTED
    }

def create_semantic_steps():
    return {
        START_STEP: STEP_NOT_STARTED,
        SEMANTIC_SEARCH_STEP: STEP_NOT_STARTED,
        PUBTRENDS_STEP: STEP_NOT_STARTED,
        SUMMARIZE_STEP: STEP_NOT_STARTED
    }
